import shutil
import time
import uuid
import warnings
from datetime import timedelta
from enum import Enum
from hashlib import file_digest
from pathlib import Path

from backpy import TimeObject, TOMLConfiguration, VariableLibrary, compression


class BackupSpaceType(Enum):
    SQL_DATABASE = {
        "name": "SQL_DATABASE",
        "description": "Backup-Space of an SQL-based database and its tables.",
    }
    FILE_SYSTEM = {
        "name": "FILE_SYSTEM",
        "description": "Backup-Space of one or more files or directories.",
    }


def _calculate_sha256sum(path: Path) -> str:
    with open(path, "rb") as f:
        digest = file_digest(f, "sha256")
    return digest.hexdigest()


class BackupSpace:
    def __init__(
        self,
        name: str,
        unique_id: uuid.UUID,
        space_type: BackupSpaceType,
        compression_algorithm: compression.CompressionAlgorithm,
        compression_level: int,
    ):
        self._uuid: uuid.UUID = unique_id
        self._name: str = name
        self._type: BackupSpaceType = space_type
        self._compression_algorithm: compression.CompressionAlgorithm = (
            compression_algorithm
        )
        self._compression_level: int = compression_level
        self._backup_dir: Path = Path(
            VariableLibrary().get_variable("paths.backup_directory")
        ) / str(self._uuid)
        self._config: TOMLConfiguration = TOMLConfiguration(
            path=self._backup_dir / "config.toml"
        )

    def create_backup(self) -> None:
        raise NotImplementedError("This method is abstract and has to be overridden!")

    def restore_state(self, unique_id: uuid.UUID) -> None:
        raise NotImplementedError("This method is abstract and has to be overridden!")

    def get_backups(self) -> list["Backup"]:
        archive_files = [
            file if file.is_file() else None
            for file in self._backup_dir.glob(
                f"*{self._compression_algorithm.extension}"
            )
        ]

        backups = []

        for archive_file in archive_files:
            try:
                backups.append(Backup.load_by_uuid(self, uuid.UUID(archive_file.stem)))
            except FileNotFoundError:
                continue

        return backups

    #####################
    #    CLASSMETHODS   #
    #####################

    @classmethod
    def load_by_uuid(cls, unique_id: uuid.UUID):
        path = Path(
            VariableLibrary().get_variable("paths.backup_directory") / str(unique_id)
        )

        if not path.is_dir():
            raise NotADirectoryError(
                f"There is no BackupSpace present with the UUID '{unique_id}'."
            )

        config = TOMLConfiguration(path=path / "config.toml")

        if not config.is_valid():
            raise FileNotFoundError(
                "The BackupSpace could not be loaded because its"
                "'config.toml' is invalid or missing!"
            )

        cls = cls(
            name=config["name"],
            unique_id=unique_id,
            space_type=config["type"],
            compression_algorithm=compression.CompressionAlgorithm.from_name(
                config["compression_algorithm"]
            ),
            compression_level=config["compression_level"],
        )
        return cls

    @classmethod
    def new(
        cls,
        name: str,
        space_type: BackupSpaceType,
        compression_algorithm: str = VariableLibrary().get_variable(
            "backup.states.default_compression_algorithm"
        ),
        compression_level: int = VariableLibrary().get_variable(
            "backup.states.default_compression_level"
        ),
    ):
        if not compression.is_algorithm_available(compression_algorithm):
            raise KeyError(
                f"The compression algorithm '{compression_algorithm}' is not available!"
            )

        cls = cls(
            name=name,
            unique_id=uuid.uuid4(),
            space_type=space_type,
            compression_algorithm=compression.CompressionAlgorithm.from_name(
                compression_algorithm
            ),
            compression_level=compression_level,
        )
        cls._backup_dir.mkdir(exist_ok=True, parents=True)
        cls._config.dump_dict(
            {
                "name": cls._name,
                "uuid": cls._uuid,
                "type": cls._type,
                "compression_algorithm": cls._compression_algorithm,
                "compression_level": cls._compression_level,
            }
        )
        cls._config.prepend_comments(
            [
                "======================================"
                "======================================",
                "   WARNING! DO NOT EDIT THIS FILE MANUALLY!"
                "THIS COULD BREAK YOUR BACKPY!",
                "======================================"
                "======================================",
            ]
        )
        return cls

    #####################
    #       GETTER      #
    #####################

    def get_uuid(self) -> uuid.UUID:
        return self._uuid

    def get_name(self) -> str:
        return self._name

    def get_type(self) -> BackupSpaceType:
        return self._type

    def get_compression_algorithm(self) -> compression.CompressionAlgorithm:
        return self._compression_algorithm

    def get_compression_level(self) -> int:
        return self._compression_level

    def get_backup_dir(self) -> Path:
        return self._backup_dir

    def get_config(self) -> dict:
        return self._config.as_dict()


class Backup:
    def __init__(
        self,
        path: Path,
        backup_space: BackupSpace,
        unique_id: uuid.UUID,
        sha256sum: str,
        created_at: TimeObject,
    ):
        self._path: Path = path
        self._backup_space: BackupSpace = backup_space
        self._uuid: uuid.UUID = unique_id
        self._hash: str = sha256sum
        self._created_at: TimeObject = created_at
        self._config: TOMLConfiguration = TOMLConfiguration(
            path.parent / (str(unique_id) + ".toml")
        )

    def create_config(self) -> None:
        self._config.create()
        self._config.dump_dict(
            {
                "uuid": str(self._uuid),
                "backup_space": str(self._backup_space.get_uuid()),
                "hash": self._hash,
                "created_at": self._created_at.isoformat(),
            }
        )

    def calculate_hash(self) -> str:
        return _calculate_sha256sum(self._path)

    def check_hash(self) -> bool:
        return self.calculate_hash() == self._hash

    def delete(self) -> None:
        self._config.get_path().unlink()
        self._path.unlink()

    #####################
    #    CLASSMETHODS   #
    #####################

    @classmethod
    def load_by_uuid(
        cls, backup_space: BackupSpace, unique_id: uuid.UUID, fail_invalid: bool = False
    ):
        path = backup_space.get_backup_dir() / (
            str(unique_id) + backup_space.get_compression_algorithm().extension
        )

        if not path.exists():
            raise FileNotFoundError(
                f"The Backup with UUID '{unique_id}' does not exist."
            )

        config = TOMLConfiguration(
            backup_space.get_backup_dir() / (str(unique_id) + ".toml")
        )

        if not config.is_valid():
            raise FileNotFoundError(
                f"The Backup with UUID '{unique_id}' could not be loaded because its"
                "'config.toml' is invalid or missing!"
            )

        cls = cls(
            path=path,
            backup_space=backup_space,
            unique_id=unique_id,
            sha256sum=config["hash"],
            created_at=TimeObject.fromisoformat(config["created_at"]),
        )

        if not cls.check_hash():
            if not fail_invalid:
                warnings.warn(
                    f"IMPORTANT! The SHA256 of the loaded backup with UUID {unique_id} "
                    "is not identical with the one saved in its configuration. "
                    "This could mean, that the file is corrupted or was changed."
                )
            else:
                raise ValueError(
                    f"The SHA256 of the loaded backup with UUID {unique_id} "
                    "is not identical with the one saved in its configuration. "
                    "This could mean, that the file is corrupted or was changed."
                )

        return cls

    @classmethod
    def new(
        cls,
        source_path: Path,
        backup_space: BackupSpace,
        exclude: list[Path] | None = None,
        verbosity_level: int = 1,
    ):

        start_time = time.time()

        if exclude is None:
            exclude = []

        unique_id = uuid.uuid4()
        created_at = TimeObject.localnow()

        if verbosity_level >= 1:
            print(f"Creating Backup with UUID '{unique_id}'...")

        archive_path = compression.compress(
            root_path=source_path,
            archive_name=str(unique_id),
            fmt=backup_space.get_compression_algorithm().name,
            level=backup_space.get_compression_level(),
            exclude=exclude,
            verbosity_level=verbosity_level,
            overwrite=True,
        )
        shutil.move(archive_path, backup_space.get_backup_dir())

        cls = cls(
            path=archive_path,
            backup_space=backup_space,
            unique_id=unique_id,
            sha256sum=_calculate_sha256sum(archive_path),
            created_at=created_at,
        )

        if verbosity_level >= 1:
            print(
                f"Created Backup with UUID '{unique_id}'. "
                f"Took {timedelta(seconds=time.time() - start_time)} seconds!"
            )

        return cls
